<!--
 * This file is part of RS Cheat Sheets.
 *
 * RS Cheat Sheets is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * RS Cheat Sheets is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with RS Cheat Sheets. If not, see <https://www.gnu.org/licenses/>.
 */
-->

[Home](../../README.md)

Not finished

# Machine Learning
- Feed data into an algorithms to improve the output.

## Theory
- There is a Model for Machine Learning(MML) that encompasses all possible machine learning algorithms.
	- Specific machine learning algorithms make assumptions about parts of this model.

### Components that make up the MML

|   |                                        |
|---|----------------------------------------|
| F | Function approximator                  |
| S | Simulation of the real world           |
| R | Randomness or Noise                    |
| C | Comparator or Error/Cost/Loss Function |
| M | Minimizer or Optimization Algorithm    |
| W | The real world                         |
| G | Has reached goal?                      |


### Function approximators
### Simulations
### Randomness
### Comparators
### Minimizers
	- Changes hyperparameters in order to minimize the error given from the 
### Real World
### Goal
	- Used to know when to brake out of the recursion



If there is no way to take the partial derivative of each variable then the evolutionary algorithm is the best optimization algorithm.
    - Is this true?
Therefore life is defined as machines who follow the evolutionary process.

Machine Learning
	- Supervised learning
		1. Function Approximation
			- Neural Network
		2. Error/Loss/Cost Function
			- Least Squares
		3. Optimization Algorithms
			- Gradient Decent
			- Evolutionary Algorithm
	- Unsupervised learning
		- Autoencoders
		- Generative Adversaria Network
		- Reinforcement Learning
